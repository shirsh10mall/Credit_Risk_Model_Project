{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY_NOTEBOOK = None\n",
    "\n",
    "\n",
    "def intitate_notebook():\n",
    "    load_dotenv()\n",
    "    global CURRENT_DIRECTORY_NOTEBOOK\n",
    "    if CURRENT_DIRECTORY_NOTEBOOK is None:\n",
    "        os.chdir(os.getenv(\"PROJECT_BASE_PATH\"))\n",
    "        CURRENT_DIRECTORY_NOTEBOOK = Path(os.getcwd())\n",
    "        print(\"Current directory for notebook: \", CURRENT_DIRECTORY_NOTEBOOK)\n",
    "    else:\n",
    "        print(\n",
    "            \"Current directory for notebook is already set: \",\n",
    "            CURRENT_DIRECTORY_NOTEBOOK,\n",
    "        )\n",
    "\n",
    "intitate_notebook()\n",
    "\n",
    "from src.utils.common import clear_gc\n",
    "clear_gc()\n",
    "\n",
    "TRAIN_PARQUET_FOLDER_PATH = (\n",
    "    \"raw_main_dataset/home-credit-credit-risk-model-stability/parquet_files/train\"\n",
    ")\n",
    "\n",
    "CLEANED_DATASET_DIRECTORY_PATH = Path(\"datasets/cleaned_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.common import import_parquet_file, count_unique_values\n",
    "from src.data_preprocessing import process_dates, fill_missing_values, drop_single_unique_columns, check_contains_negative_value, convert_boolean_to_integer, convert_categorical_to_integers\n",
    "from src.data_cleaning import get_column_description, get_columns_high_missing_values, row_missing_value_analysis\n",
    "from pyspark.sql import SparkSession\n",
    "from src.data_cleaning import column_stats\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import DateType\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, spark = import_parquet_file(\n",
    "    file_path = CURRENT_DIRECTORY_NOTEBOOK / CLEANED_DATASET_DIRECTORY_PATH / Path(\"combined_clean_data\"),\n",
    "    app_name=\"Full_Dataset_Base_ML_Model_Training\"\n",
    ")\n",
    "\n",
    "# train_df = df.filter((df.WEEK_NUM != 9) | (df.WEEK_NUM != 8) | (df.WEEK_NUM != 7))\n",
    "# test_df = df.filter((df.WEEK_NUM == 9) | (df.WEEK_NUM == 8) | (df.WEEK_NUM == 7))\n",
    "# train_df.count(), test_df.count()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.WEEK_NUM>=70)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Columns with Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns_name = [\n",
    "    \"birth_259D\",\n",
    "    # \"dateofcredend_289D_num_group_0\",\n",
    "    # \"dateofcredstart_739D_num_group_0\",\n",
    "    # \"lastupdate_1112D_num_group_0\",\n",
    "    \"creationdate_885D\",\n",
    "    \"firstnonzeroinstldate_307D\",\n",
    "    \"min_tax_registry_date\",\n",
    "    \"max_tax_registry_date\"\n",
    "]\n",
    "\n",
    "df = process_dates(df=df, date_columns=date_columns_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\n",
    "    \"dateofbirth_337D\", # similar to birth_259D, also contains missing values (~ 9%)\n",
    "    \"date_decision\", # it is not to feature as it comes from date_decisiion, which comes after labeling or predictions.\n",
    "    \"WEEK_NUM\", # Only used for Chunking # it is not to feature as it comes from date_decisiion, which comes after labeling or predictions.\n",
    "    \"base_date\", # temporary column\n",
    "    \"case_id\", # All values are unique\n",
    "    \"education_1103M\", # similar to education_927M\n",
    "    \"education_88M\", # similat to education_927M\n",
    "    \"maritalst_893M\", # similar to maritalst_385M\n",
    "    \"num_group1\", # Not required\n",
    "    \"num_group1_num_group_0\", # Not required\n",
    "    \"num_group1_num_group_1\", # Not required\n",
    "    \"contaddr_matchlist_1032L\" # It contains only False or None\n",
    "]\n",
    "\n",
    "df = df.drop(*features_to_drop)\n",
    "df = drop_single_unique_columns(df)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temp\n",
    "# for column_name in df.columns:\n",
    "#     min_value = df.agg({column_name: 'min'}).collect()[0][0]\n",
    "#     if type(min_value) is float and min_value < 0:\n",
    "#         print( f\"Column Name: {column_name}\\nMin. Value: {min_value}\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Categorical Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_values_datatype = {}\n",
    "\n",
    "# for column in tqdm(df.columns):\n",
    "#     temp_col = df.select(column)\n",
    "#     col_data_type = temp_col.dtypes[0]\n",
    "#     if col_data_type[1] not in [\"string\"]: # [\"int\", \"float\", \"date\", \"bigint\", \"double\", \"boolean\", \"string\"]:\n",
    "#         unique_values_datatype[column] = {\n",
    "#             \"unique_values_count\": temp_col.distinct().count(),\n",
    "#             \"data_type\": col_data_type[1],\n",
    "#             # \"unique_values\": [ row[0] for row in temp_col.distinct().collect() if row[0] is not None ]\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_values_datatype_sorted = sorted(unique_values_datatype.items(), key=lambda item: item[1]['unique_values_count'], reverse=False)\n",
    "\n",
    "# for item in unique_values_datatype_sorted:\n",
    "#     if len(df.select(item[0]).distinct().collect()):\n",
    "#         unique_values = [ row[0] for row in df.select(item[0]).distinct().collect() if row[0] is not None ]\n",
    "#         print(\"Column Name: \", item[0], \"\\nNumber of unique values: \", item[1]['unique_values_count'], \"\\nData type: \", item[1]['data_type'], \"\\nUnique_values: \", unique_values[:10], \"\\n\", \" - \"*25, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_boolean = [\n",
    "    \"contaddr_smempladdr_334L\",\n",
    "    \"safeguarantyflag_411L\",\n",
    "    \"isbidproduct_390L\"\n",
    "]\n",
    "\n",
    "categorical_columns_string = [\n",
    "    'description_5085714M',\n",
    "    'maritalst_385M',\n",
    "    'contaddr_district_15M',\n",
    "    'contaddr_zipcode_807M',\n",
    "    'education_927M',\n",
    "    'empladdr_district_926M',\n",
    "    'empladdr_zipcode_114M',\n",
    "    'incometype_1044T',\n",
    "    'language1_981M',\n",
    "    'registaddr_district_1083M',\n",
    "    'registaddr_zipcode_184M',\n",
    "    'role_1084L',\n",
    "    'sex_738L',\n",
    "    'type_25L',\n",
    "    'classificationofcontr_13M_num_group_0',\n",
    "    'classificationofcontr_400M_num_group_0',\n",
    "    'contractst_545M_num_group_0',\n",
    "    'contractst_964M_num_group_0',\n",
    "    'description_351M_num_group_0',\n",
    "    'financialinstitution_382M_num_group_0',\n",
    "    'financialinstitution_591M_num_group_0',\n",
    "    'purposeofcred_426M_num_group_0',\n",
    "    'purposeofcred_874M_num_group_0',\n",
    "    'subjectrole_182M_num_group_0',\n",
    "    'subjectrole_93M_num_group_0',\n",
    "    'classificationofcontr_13M_num_group_1',\n",
    "    'classificationofcontr_400M_num_group_1',\n",
    "    'contractst_545M_num_group_1',\n",
    "    'contractst_964M_num_group_1',\n",
    "    'description_351M_num_group_1',\n",
    "    'financialinstitution_382M_num_group_1',\n",
    "    'financialinstitution_591M_num_group_1',\n",
    "    'purposeofcred_426M_num_group_1',\n",
    "    'purposeofcred_874M_num_group_1',\n",
    "    'subjectrole_182M_num_group_1',\n",
    "    'subjectrole_93M_num_group_1',\n",
    "    'cancelreason_3545846M',\n",
    "    'credtype_587L',\n",
    "    'district_544M',\n",
    "    'education_1138M',\n",
    "    'inittransactioncode_279L',\n",
    "    'postype_4733339M',\n",
    "    'profession_152M',\n",
    "    'rejectreason_755M',\n",
    "    'rejectreasonclient_4145042M',\n",
    "    'status_219L',\n",
    "    'tax_registry_provider'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_unique_values = []\n",
    "\n",
    "# for key, value in unique_values_datatype.items():\n",
    "#     if \"_num_group_0\" in key or \"_num_group_1\" in key:\n",
    "#         column_name = key[:-12]\n",
    "#     else:\n",
    "#         column_name = key\n",
    "#     get_column_description(column_name)\n",
    "    # print(\"Column Name: \", column_name, \"\\nColumn Description: \", get_column_description(column_name)) #value['data_type'])\n",
    "\n",
    "#     # all_unique_values = all_unique_values + value['unique_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# def find_elements_in_at_least_two_keys(dictionary: dict) -> set:\n",
    "#     \"\"\"\n",
    "#     Find elements that are present in at least two keys of the dictionary.\n",
    "\n",
    "#     :param dictionary: Dictionary with list values\n",
    "#     :return: Set of elements that appear in at least two keys\n",
    "#     \"\"\"\n",
    "#     # Create a dictionary to count the number of keys each element appears in\n",
    "#     element_counts = defaultdict(int)\n",
    "    \n",
    "#     # Iterate through each key-value pair in the dictionary\n",
    "#     for key, values in dictionary.items():\n",
    "#         # Use a set to keep track of elements in the current key to avoid counting duplicates\n",
    "#         seen_elements = set()\n",
    "#         for element in values['unique_values']:\n",
    "#             if element not in seen_elements:\n",
    "#                 element_counts[element] += 1\n",
    "#                 seen_elements.add(element)\n",
    "    \n",
    "#     # Find elements that appear in at least two keys\n",
    "#     result = {element: count for element, count in element_counts.items() if count >= 2}\n",
    "#     result = sorted(result.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "#     # Create a new dictionary from the sorted items\n",
    "#     result = dict(result)\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# result = find_elements_in_at_least_two_keys(unique_values_datatype)\n",
    "# len(result)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_boolean_to_integer(\n",
    "    df = df,\n",
    "    boolean_cols = categorical_columns_boolean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_categorical_to_integers(\n",
    "    df = df,\n",
    "    categorical_cols = categorical_columns_string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values_dict = get_columns_high_missing_values(\n",
    "#     df = df,\n",
    "#     threshold=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([ df.schema[col_name].dataType for col_name in df.columns ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_having_negative_values = check_contains_negative_value(df)\n",
    "# column_having_negative_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_dict = get_columns_high_missing_values(\n",
    "    df = df,\n",
    "    threshold=None\n",
    ")\n",
    "\n",
    "columns_to_drop = [ key for key, value in missing_values_dict.items() if value>=10] \n",
    "df = df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_having_negative_values = check_contains_negative_value(df)\n",
    "column_having_negative_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_missing_values(df, fill_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)\n",
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark_rf = SparkSession.builder.appName(\"RandomForestBaseModel\").getOrCreate()\n",
    "# spark_rf.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.columns\n",
    "target_col = feature_cols.pop(feature_cols.index('target'))\n",
    "# target_col, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=target_col)\n",
    "\n",
    "# Create a pipeline to streamline the process\n",
    "pipeline = Pipeline(stages=[assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = df.randomSplit([0.7, 3]) # , seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values_dict = get_columns_high_missing_values(\n",
    "#     df = train_data,\n",
    "#     threshold=None\n",
    "# )\n",
    "\n",
    "train_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "train_predictions = model.transform(train_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=target_col, rawPredictionCol=\"rawPrediction\")\n",
    "auc_roc_score = evaluator.evaluate(\n",
    "    train_predictions,\n",
    "    {evaluator.metricName: \"areaUnderROC\"}\n",
    ")\n",
    "\n",
    "print(f\"AUC ROC Score: {auc_roc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=target_col, rawPredictionCol=\"rawPrediction\")\n",
    "auc_roc_score = evaluator.evaluate(\n",
    "    test_predictions,\n",
    "    {evaluator.metricName: \"areaUnderROC\"}\n",
    ")\n",
    "\n",
    "print(f\"AUC ROC Score: {auc_roc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model - SparkML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost.spark import SparkXGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor = SparkXGBClassifier(\n",
    "#   features_col=feature_cols,\n",
    "#   label_col=target_col,\n",
    "#   num_workers=2,\n",
    "#   device=\"cuda\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_df = model.transform(test_data)\n",
    "# predict_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model - Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.toPandas()\n",
    "X_test = test_data.toPandas()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[['target']]\n",
    "y_test = X_test[['target']]\n",
    "X_train = X_train.drop(columns=['target'])\n",
    "X_test = X_test.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "logger.info(\"Training the XGBoost model.\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "logger.info(\"Making predictions on the test set.\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "logger.info(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "logger.info(f\"AUC-ROC Score: {auc_roc:.4f}\")\n",
    "logger.info(\"Classification Report:\")\n",
    "logger.info(\"\\n\" + classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "logger.info(\"Making predictions on the test set.\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "logger.info(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "logger.info(f\"AUC-ROC Score: {auc_roc:.4f}\")\n",
    "logger.info(\"Classification Report:\")\n",
    "logger.info(\"\\n\" + classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "logger.info(\"Random Forest classifier initialized.\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "logger.info(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "logger.info(\"Making predictions on the test set.\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "logger.info(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "logger.info(f\"AUC-ROC Score: {auc_roc:.4f}\")\n",
    "logger.info(\"Classification Report:\")\n",
    "logger.info(\"\\n\" + classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit_risk_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
